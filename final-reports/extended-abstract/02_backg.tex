% A Theory section should extend, not repeat, the background to the
% article already dealt with in the Introduction and lay the
% foundation for further work.

\section{Optimization Algorithms}
\label{sec:backg}

Optimization algorithms can be classified differently according to their properties. One important classification regards the extent of the search for optimal solutions, which can be global or local. Local optimization algorithms strive to find a locally optimal solution, i.e., for which the objective function yields a better value than for all the other solutions in its vicinity. Moreover, local algorithms are usually highly sensitive to the starting point of the search and they tend to focus on smaller regions of the solution space. In contrast, global optimization algorithms strive to find globally optimal solutions, i.e., the best of all the locally optimal solutions. To that end, these algorithms explore larger regions of the solution space and typically require several evaluations to find global optima. However, the increased number of evaluations can be problematic in problems involving expensive objective functions. To minimize this impact, a good approach might be to apply a global algorithm to identify a promising region and then apply a local algorithm to more rapidly find the optima within that region. 

A second classification differentiates deterministic and stochastic algorithms depending on the determinism of the algorithms' outcomes. Given the same starting point and configuration, deterministic algorithms systematically apply the same sequence of steps and, as a consequence, they always return the same result. In contrast, stochastic algorithms include some form of randomness within their description and, therefore, often yield different results for the same starting point and algorithm's configuration.

The third, and final, distinction is between derivative-based and derivative-free algorithms, which differ in the type of information used during the search. Derivative-based (or gradient-based) algorithms explore information from the derivatives of objective functions, i.e., the direction and magnitude of the greatest increase of the function, to guide the search. % Consequently, they solve problems explicitly defined through mathematical forms very efficiently, as the derivatives' information is easily available. 
However when the objective function's analytical form is unknown and the derivatives are unavailable, these algorithms cannot be applied. Although finite-difference methods could be applied to approximate the derivatives, these require several extra function evaluations, which becomes impractical for problems involving expensive objective functions. In these cases, it becomes necessary to resort to derivative-free algorithms, which, instead of exploiting information about derivatives, treat the objective functions as \textit{black-boxes} and use the result of previously evaluated solutions to guide the search~\cite{Rios2013}.

Derivative-free optimization algorithms, commonly known as black-box optimization algorithms within the architectural community \cite{Wortmann2016BBO},
can treat the results of performance simulations as the functions to optimize and, consequently, avoid the difficulty of deriving analytical formulas describing building performance \cite{Machairas2014}.

For the past decades, the constant development and improvement of derivative-free optimization resulted in the creation of algorithms with different underlying assumptions and different properties. Although there is no standardized classification for these optimization algorithms~\cite{Rios2013, Wortmann2017ADO}, it is possible to group them according to their main mechanisms and ideas. This dissertation follows the classification proposed in the context of architectural design~\cite{Wortmann2015AdvSBO}, which first subdivides the algorithms according to the search strategy's determinism, namely, metaheuristics and iterative methods, and only then proceeds to partition the latter into direct-search and model-based methods, based on the function explored to guide the search. Albeit the apparent chasm between these classifications, some algorithms draw ideas from distinct classes, thus emphasizing not only the blurred lines of such categorizations, but also the difficulties that lie within the definition of more standardized classifications. 

The following subsections describe the classes of algorithms that will be explored in this dissertation, including the three classes of derivative-free algorithms: direct-search, metaheuristics, and model-based. For each section, a summarized explanation about the most relevant algorithms will also be provided. 

\subsection{Direct-search Algorithms}
Although there seems to be no precise definition for direct-search algorithms, these are often identified as algorithms that iteratively: (1) evaluate a sequence of candidate solutions, proposed by a deterministic strategy; and (2) select the best solution obtained up to that time \cite{Conn2009}. They are regarded as valuable tools to address complex optimization problems, not only because most of them were proved to rely on solid mathematical principles, but also due to their good performance at initial stages of the search process~\cite{Rios2013}. 

The main limitations of these algorithms is their performance deterioration with the increase on the number of input variables and their slow asymptotic convergence rates as they get closer to the optimal solution~\cite{Kolda2003}. Despite the existence of algorithms and benchmarks comparing \ac{SOO} direct-search algorithms \cite{Wortmann2017GABESTCHOICE,Waibel2018}, only recently have these started to appear in the context of \ac{MOO}~\cite{Custodio2010,Custodio2018}. 

Undoubtedly, one of the most relevant direct-search algorithms is the \textit{\ac{NMS}} \cite{Nelder1964}. \textit{\ac{NMS}} is a local \ac{SOO} direct-search algorithm that exploits a simplex to guide the search towards a locally optimal solution. The \textit{\ac{NMS}} algorithm envelopes a region of the design space using a simplex, which is a generalization of a triangle to arbitrary dimensions, i.e., a triangle in two dimensions, a tetrahedron in three dimensions, etc. The simplex is then successively modified using operations, like reflection, expansion, contraction, and shrinking, that iteratively replace the simplex's worst vertex values. % http://www.scholarpedia.org/article/Nelder-Mead_algorithm
Unlike other direct-search algorithms, \textit{\ac{NMS}} requires no more than two function evaluations per iteration, except when applying the shrinking operation. The initial simplex highly influences the performance of the algorithm: while smaller initial simplices often lead to local searches that converge towards a local optimum, larger initial simplices allow the algorithm to cover a larger extent of the solution space, thus becoming more robust to local optima.

Another interesting simplex-based algorithm is \textit{SUBPLEX} \cite{Rowan1990}, which attempts to overcome the \textit{\ac{NMS}} difficulties when addressing higher dimensional problems by decomposing the problem in low\nobreakdash-\hspace{0pt}dimensional
subspaces. To that end, \textit{SUBPLEX} subdivides the design space in low-dimensional subspaces and then applies the \textit{\ac{NMS}} algorithm to the most promising subspaces, in order to seek for a better solution. %In contrast to \ac{NMS}, which has difficulties in high-dimensional problems, \textit{SUBPLEX} reduces the limitations through the decomposition of the problem in low-dimensional subspaces which are more efficiently optimized by \ac{NMS}.
In the same vein, \textit{\ac{PRAXIS}} \cite{Brent1973} also decomposes the problem in smaller ones, by considering each dimension of the solution space separately. Concretely, \textit{\ac{PRAXIS}} moves from one solution to another by iteratively finding better solutions in every other dimensions and then combining them into a candidate solution. 

Besides the local algorithms discussed so far, \textit{\ac{DIRECT}} is a very promising global algorithm. \textit{\ac{DIRECT}} \cite{Jones1993DIRECT} is a \ac{SOO} algorithm which recursively subdivides the design space into smaller multidimensional hyper-rectangles, each represented by a solution in their centre. For each solution, the objective function is evaluated, thus yielding an estimate of the quality of each rectangle. Based on these values, \textit{\ac{DIRECT}} focus the search on more promising regions of the design space, further subdividing those. To minimize the overall number of function evaluations, \cite{Gablonsky2001} suggested a modification to \textit{\ac{DIRECT}} to make it more efficient for functions with few local optima and a single global optimum. This modified algorithm, called \textit{\ac{DIRECT}-L}, differs from the original one by grouping the hyper-rectangles based on the size of the longest rectangle side and by allowing at most one subdivision in each group, i.e., at most one hyper-rectangle of each group can be subdivided in each iteration. These modifications to the original algorithm promote the reduction of the number of divisions, which has a direct impact on the overall number of function evaluations.

\textit{\ac{DMS}} \cite{Custodio2010} is a global multi-objective direct-search algorithmic framework which combines the main ideas of directional direct-search algorithms with the Pareto dominance concepts. In simple terms, \textit{\ac{DMS}} maintains a list of feasible nondominated solutions and their associated step sizes. Then, it iteratively selects nondominated solutions from this list and evaluates a few solutions along a predefined set of directions located at a distance determined by the solution's step size. If during the exploration better solutions are found, then the list is updated. On the other hand, if no better solutions are found, the associated step size is reduced. The process then repeats. This algorithmic framework extends to \ac{MOO} the directional type direct-search algorithms, such as pattern search \cite{Kolda2003}, among others. In addition to \textit{\ac{DMS}}, we refer \cite{Custodio2018} to the interested reader for a more recent direct-search \ac{MOOA}.

Overall, direct-search algorithms are not as popular as other classes of derivative-free algorithms. Nevertheless, their convergence proofs and the recent developments in the field of \ac{MOO} make this class very appealing for \ac{BPO}. 

\subsection{Metaheuristics Algorithms}

Metaheuristics are algorithms that employ simple mechanisms, called heuristics, to locate good solutions in complex design spaces, while considering the trade-off among precision, quality, and computational effort of the solutions \cite{Glover2003Metaheuristics}. These algorithms often rely on randomization, and biological or physical analogies to perform robust searches and to escape local optima. Additionally, through these heuristics, the designer is able to increase the overall performance by adding domain-specific knowledge. Moreover, their non-deterministic and inexact nature confer them the ability to effortlessly handle complex and irregular objective functions \cite{Wortmann2017GABESTCHOICE}.

These algorithms often rely on randomization, and biological or physical analogies, to perform robust searches and escape local optima~\cite{Glover2003Metaheuristics}. Additionally, their stochastic nature confers them the ability to effortlessly handle complex and irregular objective functions, to adapt to \ac{MOO} contexts, or to provide domain-specific knowledge through heuristics \cite{Wortmann2017GABESTCHOICE}.

\subsection{Model-based Algorithms}