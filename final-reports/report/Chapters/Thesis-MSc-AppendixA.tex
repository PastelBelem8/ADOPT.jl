% #############################################################################
% This is Appendix A
% !TEX root = ../main.tex
% #############################################################################
\chapter{Algorithms' Definitions}
\label{appendix:AlgorithmsDefinitions}

A very summarized explanation will be provided for the optimization algorithms studied during this dissertation. Therefore, we suggest \cite{BlumRoli2003Metaheuristics,Glover2003Metaheuristics,Zhou2011} for more complete explanations on metaheuristic algorithms, \cite{Koziel2011} for model-based algorithms, and \cite{Conn2009,Custodio2010,Custodio2018} for direct-search algorithms.

\section{Sampling Algorithms} 
\begin{itemize}
\item \textbf{Full-factorial} generates a complete set of design solutions. Each dimension is described by a discrete set of values, called \textit{levels}. All possible combinations of these levels are generated and used to represent the design space and, thus, minimize errors when running full-factorial techniques multiple times. The number of generated samples scales exponentially with the number of dimensions. 
	
\item \textbf{Monte Carlo Sampling} (or Random Sampling)~\cite{Giunta2003DOE}, originally known as pseudo-Monte Carlo sampling or pseudo-pandom sampling, generates designs randomly. It frequently yields large unexplored regions of the design space. To circunvent this limitation, users should generate several hundreds or thousands of solutions.

\item \textbf{Stratified Monte Carlo Sampling}~\cite{Giunta2003DOE} yields a more uniform sampling of the design space. Each dimension of the design space is subdivided into bins of equal probability and, then, a sample is randomly selected from each bin. Provides better coverage of the design space and allows the user to select the number of bins to create in each dimension. However, the number of generatesd samples scales exponentially with the number of dimensions.

\item \textbf{Latin Hypercube Sampling} (LHS)~\cite{Giunta2003DOE} provides a better distribution of the generated samples by subdividing each dimension in equally sized bins. The generated samples are randomly placed in different bins, so that when observing the one-dimensional projections of the samples and bins, there is only one sample in each bin. The number of samples scales linearly with the number of dimensions.

\end{itemize}

\section{Direct-Search Algorithms}
\begin{itemize}
	\item \textbf{Nelder-Mead Simplex} (NMS)~\cite{Nelder1964} is a local direct-search algorithm that exploits a simplex to enforce convergence towards an optimal solution. The NMS algorithm envelopes a region of the design space using a geometric figure, called simplex, which is a generalization of a triangle or tetrahedron to arbitrary dimensions (e.g., a triangle in two dimensions or a tetrahedron in three dimensions). The simplex is then successively modified using operations, like reflection, expansion, contraction, and shrinking, that iteratively replace the simplex's worst vertex values. Unlike other direct-search algorithms, NMS requires no more than two function evaluations per iteration, except when applying the shrinking operation. The initial simplex has a high impact on the algorithm's performance, particularly, smaller initial simplices frequently lead to local searches and, consequently, to local optimum.
	
	\item \textbf{Subspace simplex} (Subplex)~\cite{Rowan1990} algorithm is an unconstrained local optimization algorithm~\cite{Rowan1990}. As a generalization of the NMS algorithm, SUBPLEX subdivides the design space in low-dimensional subspaces and then applies the NMS algorithm to the most promising subspaces, in order to seek for a better solution. In contrast to NMS, which has difficulties in high-dimensional problems, SUBPLEX reduces the limitations through the decomposition of the problem in low-dimensional subspaces which are more efficiently optimized by NMS.
	
	\item \textbf{Principal Axis} (PRAXIS)~\cite{Brent1973} moves from one region to other by iteratively applying line search algorithms to each direction. The goal of these line search algorithms is to determine a better solution along a certain dimension. It is a local algorithm, which strongly depends on a good initial point.
	
	\item \textbf{DIRECT}~\cite{Jones1993DIRECT} is an algorithm that recursively subdivides the design space into smaller multi-dimensional hyper-rectangles, estimating the quality value of each rectangle. DIRECT uses these values to focus the search on more promising regions of the design space and to further subdivide those in smaller hyper-rectangles. DIRECT is designed to fully explore the variable space, even after finding one or more local optima.
	
	\item \textbf{DIRECT-L} \cite{Gablonsky2001} is a a local variant of DIRECT claimed to be more efficient for functions with few local optima and a single global optimum. The main differences to the original DIRECT algorithm are that DIRECT-L groups the hyper-rectangles based on the size of the longest rectangle side and that there is at most one subdivision in each group, i.e., at most one hyper-rectangle of each group can be subdivided in each iteration. These modifications to the original algorithm promote the reduction of the number of divisions, which has a direct impact on the overall number of function evaluations.
	
	\item \textbf{Direct MultiSearch} DMS \cite{Custodio2010} is a global multi-objective direct-search algorithmic framework which combines the main ideas of directional direct-search algorithms with the Pareto dominance concepts. It maintains a list of feasible nondominated solutions and corresponding step size parameters, which is iteratively updated during the optimization process. From this list, it explores the vicinities of a selected nondominated solution using the associated step size and a predefined set of directions. During the local search around the selected solution, it creates a temporary list of points that contains all the solutions of the first list and the solutions evaluated during this search. The temporary list is then filtered removing any unfeasible or dominated solution. If the temporary list differs from the first list, then it means that better solutions were found and, consequently, the first list is replaced by the temporary one and the process repeats.  On the other hand, if the temporary list equals the first list, it means that the local search was not able to find a better solution and the step size associated to this solution should be reduced. The process then repeats. This algorithmic framework extends to \ac{MOO} the directional direct-search algorithms, including the generalized pattern search and mesh generating set search~\cite{Kolda2003}, among others. 
	 %https://www.mat.uc.pt/~lnv/papers/dms.pdf
	% http://ferrari.dmat.fct.unl.pt/personal/alcustodio/multiglodspaper.pdf


\end{itemize}	

\section{Metaheuristics Algorithms}
\begin{itemize}
	
	\item \textbf{Simulated Annealing} \cite{Brownlee2011} is a global optimization physical algorithm. Resemblant of hill climbing algorithms, where new candidate solutions are randomly sampled, this algorithm iteratively re-samples the solution space aiming at finding an optimal solution. During the search, the algorithm is propitious to accept the re-sampled solutions with lower performance, according to a probabilistic function that becomes more discerning of the quality of the samples over the execution of the algorithm, thus resembling the natural annealing process. 
	
	\item \textbf{Controlled Random Search 2} (CRS2) algorithm is a variant of the CRS algorithm for global optimization~\cite{Price1983}. A CRS algorithm is a population-based random search algorithm that creates an initial set of points, the population, which are then randomly evolved by means of heuristic rules. In the original CRS algorithms, heuristic rules modify a point at a time, replacing the worst point with a better one (called trial point), using a technique resemblant of the NMS algorithm \cite{Nelder1964}. Similarly to NMS, CRS algorithms use a simplex, i.e., a generalized triangle in $N$ dimensions, to envelope a region described by a random subset of points in the population. The worst point of the population is replaced with the reflection of the worst point in the simplex~\cite{Kaelo2006CRS2}. The CRS2 variant differs from the original in that it assumes that the worst population point will always be a part of the simplex. One variant of the CRS2 algorithm introduces a local mutation component in an attempt to overcome situations,  where heuristic rules constantly fail to find a trial points that actually improve the worst point. Fundamentally, this local mutation generates a second trial point that results from the exploitation of the region around the best point in the population~\cite{Kaelo2006CRS2}.  
	
	\item \textbf{Evolutionary Strategy with Cauchy Distribution} (ESCH) \cite{Santos2010} explores evolutionary strategies to seek more efficient solutions. Initially, it creates a population that is iteratively recombined during the optimization according to a non-uniform distribution function and then mutated using a combination of two different mutation operators, such as the Gaussian variation and the gene duplication.
	
	\item \textbf{Improved Stochastic Racking Evolutionary Strategy} (ISRES) \cite{Runarsson2000} is a global evolution strategy method that evolves candidate solutions by stochastically ranking and selecting the best solutions, i.e., a method that maximizes the suitability of the candidate designs given by a fitness ranking function. The candidate designs are evolved iteratively by combining the application of a mutation rule and differential variation.
			
	\item \textbf{Covariance Matrix Adaptation - Evolutionary Strategy} (CMA-ES) \cite{Hansen2006} is a descendent of the evolutionary strategies, whose candidate solutions are sampled according to normal distributions and recombination and mutation amount to selecting new mean values for the distribution and to adding perturbations with zero mean, respectively. CMA-ES maintains a covariance matrix with the pairwise dependencies between the variables in the distribution which is updated using a technique called covariance matrix adaptation (CMA) which attempts to incrementally update the likelihood of previously successful candidate solutions.
	
	\item \textbf{SPEA2} \cite{Zitzler2001SPEA2} is a \ac{MOEA} that incorporates evolutionary mechanisms to incrementally evolve a population from generation to generation. In addition to the population, SPEA2 maintains a set of optimal solutions called archive. While a stopping criteria is not met, the archive is continuously updated by ranking each individual of the population according to the solutions it dominates. Any dominated solution will be removed from the archive and, in case the archive exceeds its size, a clustering technique selects individuals in more crowded regions of the objective space for removal. Binary tournaments are then carried between elements in the archive and population to select the individuals for reproduction and to create the individuals for the next generation, i.e., the offspring. These individuals result from the recombination and mutation of the best individuals from the previous iteration. 
	
	\item \textbf{NSGA-II} \cite{Deb2002} is aa \ac{MOEA} that also incorporates evolutionary mechanisms to incrementally evolve a population. Similarly to SPEA2, NSGA-II evolves a population and maintains an archive of the optimal solutions. Every generation, a population is evaluated and each individual is sorted according to their nondominated ranking, 
	
	\item \textbf{Epsilon \ac{MOEA}} ($\epsilon$-MOEA) 
	
	\item \textbf{Hypervolume Estimation Algorithm for \ac{MOO}} (HypE)~\cite{Zitzler2011HypE} an algorithm that explores the \ac{HV} indicator to rank individuals. Particularly, to minimize time penalties associated with the computation of the \ac{HV}, in scenarios with more than three objectives, HypE uses Monte Carlo simulations to estimate the \ac{HV} value of each individual.
% 	Unfortunately, algorithms incorporating the Pareto dominance relation and diversity measures appear to have difficulties in optimization scenarios with more than two objectives, which spurred the development of algorithms using other quality measures, including quality indicators. To overcome the objective limitation and provide the user with the flexibility to use a more efficient algorithm, Octopus provides the option to use HypE, an algorithm that explores the \ac{HV} indicator to rank individuals. Particularly, to minimize time penalties associated with the computation of the \ac{HV}, in scenarios with more than three objectives, HypE uses Monte Carlo simulations to estimate the \ac{HV} value of each individual~\cite{Zitzler2011HypE}. 
	
	\item \textbf{\ac{MOEA} with Decomposition} (MOEA/D)
	
	\item \textbf{Pareto Archived Evolution Strategy} (PAES) is a \ac{MOEA} which explores \acp{ES} on populations composed of a single individual and maintains an archive with previously found solutions to identify the approximate dominance ranking of the current and candidate solution vectors. In every iteration, the candidate solution is compared with respect to the current solution and depending on whether the candidate dominates the current solution or not, the current solution will be updated or a new candidate solution is found through mutation. In the case where none of the solutions dominate each other, each solution is compared against an archive of the nondominated solutions and if the candidate solution dominates any of the solutions in the archive, it will be accepted as the new current solution and the dominated solutions are removed from the archive, otherwise, the selection of the new current solution will be based on how crowded each solution is, when compared to the solutions in the archive. 
		
	\item \textbf{Pareto Envelope-Based Selection Algorithm 2} (PESA2)
	
	\item \textbf{Speed-constrained Multi-objective \ac{PSO}} (SMPSO)
	
	\item \textbf{OMOPSO}
	
\end{itemize}

\section{Model-based Algorithms}
\begin{itemize}
	\item \textbf{GPR-based} algorithms rely on guassian process (GP) techniques, which generalize Gaussian probability distributions to functions. GP algorithms incorporate a measure of the similarity between points, called the kernel function, to predict the value for an unseen point from training data. Besides the prediction of the value, GPs provide a measure of the associated uncertainty.
	
	\item \textbf{MLP-based} algorithms consist on the creation of surrogate models using \acp{MLP}. \ac{MLP} is a class of feedforward neural networks that comprises at least three layers of nodes, including one input layer, one output layer, and, at least, one hidden layer. In neural networks, all nodes with the exception of the input nodes are called neurons and each node possesses a non-linear activation function. These non-linearities provide the networks the ability to approximate non-linear and extremely complex functions. These \acp{MLP} models are trained using a supervised learning technique, where the model is provided with the input variables' values and the outcome that was observed for those input values. The model is then updated using a technique called backpropagation which uses the error rates between the obtained outcome and the expected outcome to correct the neurons and improve the \ac{MLP} model. 
	
	\item \textbf{RBF-based} algorithms consist on the creation of surrogate models using \acp{RBF}. Since its invention, multiple implementations of \ac{RBF} have been proposed. RBFOpt implements two well-known versions, namely, the Gutmann's~\cite{Gutmann2001} and the Regis and Shoemaker's~\cite{Regis2007}, commonly known as MSRSM. These techniques differ in the search strategy for the next candidate solution to be evaluated using the original objective function. The former uses the solution, which is likely to yield the largest improvement in the surrogate's accuracy, whereas the latter tries to balance the surrogate's accuracy amelioration with the exploitation of promising solutions, using other search strategies, such as genetic algorithms, sampling algorithms, or other mathematical solvers~\cite{Wortmann2017Opossum}. Moreover, RBFOpt provides five different types of radial basis function: linear, multi-quadratic, cubic, thin plate spline, and automatic selection, which are also provided in the Opossum interface.
		
	\item \textbf{RF-based} algorithms consist on the creation of surrogate models using \acp{RF}, also called random decision forests~\cite{Ho1995RDF}. These algorithms incorporate an ensemble learning approach that consists on applying multiple decision trees to obtain a better performance. Given a set of input variables the result of an \ac{RF} algorithm will be given by the mean  of the results returned by each individual tree. \ac{RF} are particularly sought due to their ability to correct the decision trees propensity to overfit the data, i.e., to become too specific.
	
\end{itemize}