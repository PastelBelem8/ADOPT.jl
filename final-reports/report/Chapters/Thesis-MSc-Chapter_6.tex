% #############################################################################
% This is Chapter 6
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Conclusion}
%\cleardoublepage
% The following line allows to ref this chapter
\label{chap:conclusion}

In this chapter, we reflect on the developed work and the obtained results. We draw some general conclusions about the applicability of the solution, including in its potential for the architectural practice. We end by outlining some guidelines for future work. 

% #############################################################################
\section{Conclusions}
Nowadays, with the threat of climate change, resource depletion, and worldwide urbanization, it is not enough to construct well-designed buildings, it is also necessary to optimize them \cite{Wortmann2015AdvSBO}. Architectural practices have, therefore, grown to incorporate considerations about the building's performance in various aspects, including energy consumption, comfort, and costs, among others. For the past few decades, the development of computational simulation tools empowered designers with the ability to simulate and estimate a building’s performance, prior to its construction. The emergence of these tools and the raising concerns about the environmental and economic impact of buildings led to the development of new design approaches, such as Performance-Based Design (\ac{PBD}), which seek more efficient design solutions by considering the designs’ performance. Taking design’s performance a step further, optimization has unveilled a new performance-based approach called Building Performance Optimization (\ac{BPO}). 

Unfortunately, traditional \ac{BPO} methodologies require the evaluation of different design variations, which, in turn, implies spending a large amount of time with the manual application of changes to the design and often leading to difficulties when manually modeling complex geometry. Moreover, in order to evaluate a design's performance, the corresponding analytical models must be produced, which also comprises a time-consuming and tiresome task. The emergence of algorithmic-based paradigms, like Algorithmic Design (\ac{AD}) and Algorithmic Analysis (\ac{AA}), enabled the implementation of automated optimization processes, as they allow architects to generate multiple design variants with little effort, to automatically produce the corresponding analytical models, and to automatically evaluate their performance. Notwithstanding the benefits attained with algorithmic approaches, the exploration of more efficient designs still comprises a tiresome and time-consuming task. To overcome this limitation, one can exploit the automatisms associated with optimization algorithms to more efficiently seek for optimal (or near optimal) design solutions.

Notwithstanding the automation of optimization processes, most \ac{BPO} problems require expensive simulation-based objective functions, for which a single evaluation may take a considerable amount of time to complete. In order to speed up the optimization process, it becomes necessary to identify different optimization algorithms capable of handling the computationally complex problems that characterize \ac{BPO}, and to devise strategies for its efficient application in architecture. Often disregarded, the selection of the appropriate optimization algorithm might have a significant impact in the overall efficiency of optimization processes, and also on the quality of the results \cite{Wolpert1997NFLT}. 

Despite the benefits associated with a more targeted selection of optimization algorithms, most \ac{BPO} practitioners tend to adopt evolutionary-based algorithms \cite{Evins2013, Nguyen2014}. Such algorithms typically require several hundreds or thousands of evaluations, which is an infeasible scenario for most \ac{BPO} problems. Conversely, direct-search methods and model-based algorithms are more promising, typically yielding better results in fewer evaluations \cite{Waibel2018}. One of the main advantages of model-based algorithms is their potential for reducing the overall optimization time \cite{Wortmann2017GABESTCHOICE}, as it was visible in \cref{ssec:soocasestudy}, where the application of global model-based algorithms reduced the overall optimization time, on average, in about 50\%. 

% What we did, how we tested, what were the conclusions
Along these lines, we studied different optimization approaches and algorithms to measure their affinity for problems involving expensive objective functions, where the number of function evaluations is frequently restricted to a few hundreds \cite{Caetano2018,Belem2018optimizeddesign,Belem2019MOO,IP2019MOO}. We introduced an extension to the \ac{AD} and \ac{AA} approaches, called Algorithmic Optimization (\ac{AO}), which combines an optimization framework and an \ac{AD} tool to allow users to address various design optimization problems, including \ac{BPO}. In general, we conclude that no single class, subclass, or algorithm excels at every problem, thus confirming the No Free Lunch Theorem (\ac{NFLT}) \cite{Wolpert1997NFLT}.  

Most tools and, in particular, \ac{MOO} tools, still rely on evolutionary-based algorithms. However, in the evaluated case studies, metaheuristics and, particularly, the evolutionary ones rarely achieved the best performance. In fact, other categories, such as global model-based or global direct-search algorithms yielded better results. Different factors could change the obtained results (e.g., a different configuration for the algorithms or a lucky random step). Therefore, and contrarily to current architectural practices, we conclude that distinct algorithms behave differently according to  problems' specificity and that users should test different algorithms for a small number of evaluations or for a short amount of time. 

Furthermore, we conclude that while global optimization algorithms are quicker to converge towards optimal solutions when no additional information is known, local algorithms can be quicker if provided with good starting points and, therefore, should be considered as potential candidates when such information is available.

Regarding the evaluation of different \acp{MOOA}, the lack of consensus regarding the more appropriate way to measure their quality makes it difficult to quantify the suitability of each algorithm for \ac{MOO} problems. In this study, we conclude that algorithms' quality should be measured through the combination of Pareto front plots and multiple performance indicators, namely the cardinality, diversity, and accuracy of the Pareto fronts. %In this way, the real impact of model-based algorithms in the overall optimization time is not quantifiable. To circumvent this limitation, one can measure these indicators per evaluation, similarly to what is done in \ac{SOO} contexts. However, this increases the complexity of the evaluation and requires more standardized ways to measure these algorithms' performance.
 
% Overall conclusion
Based on the conclusions regarding algorithmic efficiency, we believe architects should use several optimization algorithms in their workflow and use the optimization approach that better fits their needs and expertise. This conclusion contradicts the approach taken in some architectural optimization plug-ins, which are often limited to a unique optimization approach and to a small subset of algorithms, namely, the \acp{EA}. Unfortunately, as demonstrated, \acp{EA} are not the best choice for \ac{BPO}. To bypass this limitation, the optimization framework proposed in this dissertation includes different categories of optimization algorithms and facilitates their application by abstracting them under a common interface, thus promoting automated optimization processes. To further facilitate the selection of the most appropriate algorithm, it also includes mechanisms to test multiple optimization algorithms effortlessly. The suitability and capabilities of the framework were evaluated in the context of three \ac{BPO}, which demonstrated its ability to solve real architectural problems characterized by computationally complex objective functions.

Overall, as discussed in this dissertation, optimization can be very beneficial for architecture. The combination of simulation tools, algorithmic-based approaches, and optimization algorithms enables the automation of optimization processes within architectural practices. Despite its benefits, the incorrect application of these optimization processes can lead to poor results. Moreover, different architectural design problems benefit most from different optimization algorithms, capable of handling them more efficiently. However, existing architectural tools tend to adopt a small set of algorithms and typically focus on \ac{EA}. Results show that \acp{EA} may not be the most adequate algorithms for most problems and that other algorithms should be considered. The framework proposed in \cref{chap:architecture} overcomes these limitations by providing several optimization algorithms with different characteristics, thus fostering better optimization practices. Finally, the optimization methodology proposed in \cref{chap:implement} was shown to benefit the architectural practice, as was demonstrated by the three \ac{BPO} case studies.
	
% #############################################################################
\section{Limitations and Future Work}
This dissertation proposes a general-purpose optimization framework providing different optimization approaches and optimization algorithms particularly tailored for optimization problems including simulation-based objective functions. Although the current framework already proved valuable to address architectural problems, it can be further improved. In this section, we describe the limitations found and we suggest future lines of research.

% System Limitations
%\subsection{Limitations}
Despite providing the base functionality for addressing optimization problems, the current framework presents some limitations regarding the key aspects mentioned in \cref{ssec:AOW}, namely in terms of (1) flexibility/automation of specific optimization approaches, (2) interactivity, (3) visualization capabilities, and (4) intelligibility of results.

Firstly, notwithstanding the framework support for different optimization approaches (e.g., experimental, Pareto-based), users could also benefit from additional ones, like the prioritization of the optimization of different objectives (e.g., in a bi-objective optimization problem, optimize one objective first and only then proceed to optimize the second). 

Secondly, the current framework does not provide the mechanisms to follow a human-in-the-loop approach, where the user is able to interact and influence the optimization process. The ability to influence the course of an optimization approach would be particularly interesting in the architectural field, where architects can use recently acquired knowledge or intuitions to explore more promising regions of the design space or even to speed up the optimization process. A possible research path includes the ability to change or add constraints in real time or to specify different design variants to be explored, and to influence the search to focus in regions near selected design variants. % The idea is that the user selects a few designs and the optimization will focus on regions near the selected design variants

Thirdly, although the current visualization mechanisms provide a fair and general understanding of the results obtained in optimization processes, they present limitations concerning the visualization of Pareto fronts for problems involving more than three objectives. An important research path is how to represent the information regarding different runs of \ac{MOO} algorithms, for which users have a limited evaluation budget and cannot afford to let the algorithms run indefinitely until they converge towards an idyllic Pareto front. %\todo{Referenciar trabalho do Edward Tufte?} 

% Interesting future work
The fourth framework limitation concerns the intelligibility of the produced results. Currently available optimization tools rarely provide information regarding the optimization results, which hinders users' ability to understand them. Besides visual mechanisms and textual logs, our framework does not currently provide additional feedback to aid the user with the interpretation of the optimization results. Therefore, an interesting research path is to explore mechanisms that provide an explanation regarding the quality of the obtained results, especially when using opaque algorithms, i.e., whose non-linearity severely hinders the inteligibility of the optimization process itself. Recent advances in the field of \ac{ML} related to the algorithms' explainability are promising and can be explored to provide explanations about the different optimization algorithms. A starting point to investigate will be to exploit the log files currently produced by the framework and use one of the available model-based methods to approximate the problem and extract information about it using, for example, LRP or sensitivity analysis techniques \cite{Bach2015,Tripathy2018}.

% Transition
Besides improvements in the framework itself, we also envision other interesting research paths, namely in what concerns the tests and the studies of model-based algorithms. 

% \subsection{Future Work}
% Case studies
In fact, although the developed framework was tested in a single-objective daylight optimization case study and two bi-objective optimization case studies, one including the optimization of structural and aesthetics aspects and other incorporating the optimization of daylight and cost aspects, all three case studies involved the optimization of less than six variables with the corresponding bound constraints and at most two objectives. In the future, the proposed framework could be used to test optimization problems with higher complexity, not only in terms of variables and objectives, but also by adding other constraints. Moreover, it would be interesting to assess the performance of optimization algorithms when subject to problems involving other design aspects, including, among others, thermal, energy consumption, and acoustics. 
 
% Optimization algorithms
One other relevant research path is the evaluation of more optimization algorithms, involving different mechanisms and strategies, in order to assess their suitability for optimization problems and its impact on the overall performance of optimization processes. Additionally, as it has been partially demonstrated with the Ericeira's case study, fine-tuning and providing initial information to certain algorithms may drastically improve their performance. For this reason, evaluating the impact of different algorithm's parameters for certain optimization problems would be another relevant case study, particularly, for complex building design problems involving expensive evaluation functions. 

Furthermore, it would be interesting to study the impact of pre-training surrogate-based optimization models based on data obtained from standard optimization test functions~\cite{Zhang2009TEST}. Particularly, users could use previous knowledge about the objectives' behavior (e.g., discontinuous, multimodal, convex) and pre-train the surrogate models in similar standardized test functions, thus, potentially, accelerating optimization processes. In the same vein, testing the impact of approximating the costly evaluation functions using an ensemble of different algorithms could also be exploited to find its impact on the efficiency of the optimization process. %Despite the increased complexity of ensemble techniques, this is can, in general, be neglected in the context of \ac{BPO}, as the overall optimization time tends to be completely dominated by the costly evaluation functions. 
Another interesting study would be to evaluate the impact of using a surrogate model for each objective, instead of using a single one for all objectives. 
